---
title: "Candy1"
author: "Czuee Morey"
date: "7/24/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r pckgs, warning=FALSE, include=FALSE}
library(gridExtra)
library(grid)
library(ggplot2)
library(lattice)
library(dplyr)
library(caret)
library(caretEnsemble)
library(doParallel)
library(dlookr)
library(Hmisc)
library("FactoMineR")
library("factoextra")
```

### 1) Business Question

*The Lidl purchasing group wants to expand its candy offering, and wants to create a brand new product. Based on data from existing brand products, the goal is to find out which product characteristics drive customer sentiment and subsequently make a recommendation on a new product.*


##### 1.1) What are we trying to predict?

Which candy characteristics are correlated with the highest customer sentiment? Recommend a new candy based on these characteristics.

##### 1.2) What type of problem is it? Supervised or Unsupervised Learning? Classification or Regression? Binary or Multiclass? Univariate or Multivariate? Clustering?

This is a multivariate supervised machine learning problem in which we have to predict numeric outcomes of percentage of wins for each candy in 269,000 matchups with another candy  - hence I need to use regression techniques.

##### 1.3) What type of data do we have? 

The data is in csv format. It presents a header row with the column names. It contains binary variables and two variables in percentiles (not percentage).

##### 1.4) Import the dataset and check its size
```{r}
candy <- read.csv("candy-data.csv", header = TRUE, na.strings = c("NA"," "))
dim(candy)
# table(candy$pluribus)
# 
# identical(candy$competitorname, unique(candy$competitorname))
```
Data frame with 85 rows and 13 columns. 

### 2) Exploratory Data Analysis (EDA)

##### 2.1) View Data. Anything strange?

```{r}
str(candy)
```

```{r}
summary(candy)
```

```{r}
head(candy)
```

##### 2.2) Observations:
1. There are no NAs or missing values in the file. So, the dataset is complete and it is not required to clean any errors or missing values.
2 .Each column is "tidy", each value is placed in its own “cell”, each variable in its own column, and each observation in its own row, so we don't need to transform it.
3. The variables chocolate to pluribus are binary, but are represented as integers. Needs to be corrected.
4. "sugarpercent" is a percentile value for the dataset, not percentage of sugar content. Same for "pricepercent". We do not have information about the underlying distribution with absolute values, but only the rank in the dataset.
5.  Assumption: Competitor name is not a predictor (unless brand value drives sales) and is unique, so we can make it the row name. In any case, a brand name is not useful for Lidl to create a new candy.

#Convert binary columns to factor
```{r}
candy[ , 2:10] <- lapply(candy[ , 2:10], factor)
sapply(candy, class)
```

#Competitor name to rows
```{r}
row.names(candy) <- candy$competitorname
candy <- subset(candy, select =  -competitorname)
head(candy)
```

##### 2.2) What is our Response Variable? Study it.
```{r}
summary(candy$winpercent)
```

```{r}
dlookr::describe(candy)
```
It ranges from 22.45 to 84.18 (in percent). 

The mean is close to the median, but the median is slightly lower indicating a slight positive skew. The kurtosis is low. The sd_mean is low, and SD is lower than the mean which means that the mean is well-defined. 

The distribution for the other continuous variables is also good.

```{r}
ggplot(data = candy) +
  geom_histogram(mapping = aes(x = winpercent), binwidth = 5, boundary = 0, fill = "gray", col = "black") + 
    geom_vline(xintercept = mean(candy$winpercent), col = "blue", size = 1) +
    geom_vline(xintercept = median(candy$winpercent), col = "red", size = 1) +
    annotate("text", label = "Median = 47.83", x = 40, y = 5, col = "red", size = 5) +
    annotate("text", label = "Mean = 50.32", x = 55, y = 5, col = "blue", size = 5) +
    ggtitle("Histogram of winpercent") +
    theme_bw()
```

The distribution is not exactly normal, but we can proceed without transforming it. We can scale this variable to be on the same range as other variables (0 to 1)

```{r}
candy$winpercent <- candy$winpercent/100 
```


#Distribution of other variables
```{r}

price.h <- qplot(pricepercent, data = candy, ylab = "Frequency") +stat_bin(binwidth = 0.05) +ylim(0,15)
sugar.h <- qplot(sugarpercent, data = candy, ylab = "Frequency") +stat_bin(binwidth = 0.05) +ylim(0,15)

grid.arrange(sugar.h, price.h, nrow = 1, top=textGrob("Distribution of candy characteristics"))

```

We already saw that the mean and median for the sugar and price variables is close with low skew and kurtosis. However, there are a lot of breaks in the data or no values for certain sugar and price percentiles. This could be because:
a. Our data is sparse, with only 85 observations so certain sugar/price points will not be covered.
b. Certain unit prices like €3.99 are more preferred than a continuous range. Same could be true for spikes in sugarpercent due to rounding, etc.

```{r}
nm <- names(candy[1:9])
pltlist <- list()
for (i in seq_along(nm)) {
    pltlist[[i]] <- ggplot(candy, aes_string(x = nm[i]))+ geom_bar() + ylim(0, nrow(candy))
}

grid.arrange(grobs = pltlist, top=textGrob("Distribution of candy characteristics"))
```

Chocolate and fruity each are present in >35 candies while the other ingredients are in smaller quantities. 

More than 20% of candies are bars. Almost equal number of candies are single or present in a bag/box

```{r}
xtabs(~chocolate+fruity, data = candy)
```
Most candies have either chocolate or fruity, not both. 11 candies have neither.

#Count tables for all factors
Candies that contain chocolate - distribution of other ingredients
```{r}
candy[ ,1:9] %>% subset(chocolate == 1) %>% sapply(., summary) 
```
Chocolate candies generally don't have fruity and are not hard.

```{r}
candy[ ,1:9] %>% subset(fruity == 1) %>% sapply(., summary) 
```
Fruity candies never have bars, peanutyalmondy, nougat or crispedricewaffer and generally have no chocolate.

```{r}
candy[ ,1:9] %>% subset(bar == 1) %>% sapply(., summary)
```
Bars are never fruity, hard or present in a box/bag and generally contain chocolate.

```{r}
candy[ ,1:9] %>% subset(pluribus == 1) %>% sapply(., summary) 
```
Candies present in a box rarely have any other characteristics except fruity and sometimes hard and chocolate

```{r}
candy[ ,1:9] %>% subset(hard == 1) %>% sapply(., summary) %>% prop.table(., margin = 2)
```
Most hard candies are fruity but generally have none of the other ingredients.

```{r}
xtabs(~peanutyalmondy+caramel, data = candy)
```

Chocolate and fruity seem to be mutually exclusive. It would be interesting to see what are the candies that contain neither.

```{r}
candy[ ,1:9] %>% subset(chocolate == 0 & fruity == 0) %>% sapply(., summary)
```

#Correlation for numeric variables

Sugarpercent and pricepercent are in percentiles, so there is no requirement to center and scale these variables.
```{r}
qplot(sugarpercent, pricepercent, data = candy) + geom_point() + geom_smooth(method = lm)
#cor(candy$sugarpercent, candy$pricepercent, method = "spearman")
```
Sugarpercent and pricepercent don't have a high correlation.

```{r}
ggplot(candy) + aes(sugarpercent, pricepercent, color = bar) + geom_point() 
#+ geom_smooth(method = lm)
```
Bars have high sugarpercent and pricepercent

```{r}

df <- as.numeric(candy[ ,])

install.packages("infotheo")
infotheo::mutinformation(cbind(candy[1:9], dat))
dat <- infotheo::discretize(candy[ ,10:12])
head(dat)
```


###### Most columns seem to be necessary, and there is no column that is a replicate and can be removed.

######Feature engineering 
No new features can be added to the dataset based on the existing data. Also, the data seems to be informative and complete.
we can explore quadratic terms and interaction terms while modeling.

###### Outlier detection
```{r}
boxplot(candy[10:12], main = "Features Boxplot")
```
It looks like there are no outliers in the numeric variables

##### Transform data if needed
Most of the variables are binary. The numeric variables are already in percentile and do not need to be converted.

##### Automatic Feature extraction. Dimensionality Reduction 
We have only 12 features in our dataset, so we don't need to do any dimensionality reduction. However, I will run a categorical PCA (multiple correspondence analysis) to visualize the distance between the binarz variables.

```{r}
res.mca <- MCA(candy[ ,1:11], quanti.sup = c(10:11), ncp = 5, graph = TRUE)
```


```{r}
fviz_screeplot(res.mca, addlabels = TRUE, ylim = c(0, 45))
summary(res.mca, nb.dec = 2, ncp = 2)
```
Dimensions 1 & 2 represent `r 39.1+13.5`% variation contained in the data. 100% of the variability is captured in 9 dimensions.
Pricepercent has some contribution to Dim1 but sugarpercent seems to have very less contribution in Dim1-2.

#MCA Biplots
```{r}
fviz_mca_biplot(res.mca, 
                geom.ind = c("point"), 
               repel = T, # Avoid text overlapping (slow if many point)
               ggtheme = theme_bw())
```
The plot above shows a global pattern within the data. Rows (candies) are represented by blue points and columns (characteristics) by red triangles.

The distance between the points gives a measure of their similarity.


```{r}
grp <- as.factor(candy[ , "chocolate"])
fviz_mca_biplot(res.mca, 
                #geom.ind = c("point"), 
                select.ind = list(contrib = 30),
                habillage = grp, addEllipses = TRUE, ellipse.level = 0.95,
                select.var = list(contrib = 5),
               repel = T, # Avoid text overlapping (slow if many point)
               ggtheme = theme_bw(),
               title = "MCA Biplot clustered by chocolate"
               )
```

```{r}
plotellipses(res.mca, 
             keepvar=c(1,2,7,8), level = 0.95, 
             means = FALSE, 
             xlim = c(-2,2), ylim = c(-1.5, 1.5))
```

The top 30 contributing candies and top 5 characteristics in dimension 1 vs 2. There are two clusters- one that contain chocolate and another that do not contain chocolate (mostly fruity).

The top 5 contributors are chocolate1, fruity1, bar1, hard1 and nougat1.

#Correlation of variables with each dimension.
```{r}
var <- get_mca_var(res.mca)

fviz_mca_var(res.mca, choice = "mca.cor",
            repel = TRUE, # Avoid text overlapping (slow)
            ggtheme = theme_minimal())
```
Fruity, chocolate & bar are correlated with dimension 1, and hard, pluribus & nougat with dimension 2.

#Degree of association between variable categories and each dimension
```{r}
corrplot::corrplot(var$cos2, is.corr=FALSE, cl.lim = c(0, 1), cl.ratio = 0.7)
```
Some of the variables require more than 2 dimensions to represent all the variability. Crispedricewafer has variability represented in dimension 3. Also, we have seen that contribution of dimension 3 (12.9%) is close to the conrtibution of dimension 2 (13.5%), so we need to look into Dim3.

```{r}
grp1 <- as.factor(candy[ , "crispedricewafer"])
fviz_mca_biplot(res.mca, 
                #geom.ind = c("point"),
                axes = c(2,3),
                select.ind = list(contrib = 20),
                habillage = grp1, addEllipses = TRUE, ellipse.level = 0.95,
                select.var = list(contrib = 3),
               repel = T, # Avoid text overlapping (slow if many point)
               ggtheme = theme_bw(),
               title = "MCA Biplot clustered by crispedricewafer"
)
```
Crispedricewafer1, nougat1 and peanutyalmondy1 contribute to the most variability in Dim2-3. They are also distant from each other in these two dimensions,  while they were closer in Dim1.

```{r}
plotellipses(res.mca, keepvar=c(3:6,9), 
             level = 0.95, means = FALSE, 
             axes = c(2,3),
             xlim = c(-2,2),
             ylim = c(-2,2)
             )
```


```{r}
# Contributions of rows to dimension 1
fviz_contrib(res.mca, choice = "var", axes = 1, top = 15)
# Contributions of rows to dimension 2
fviz_contrib(res.mca, choice = "var", axes = 2, top = 15)
# Contributions of rows to dimension 2
fviz_contrib(res.mca, choice = "var", axes = 3, top = 15)

```
The red dashed line on the graph above indicates the expected average value, If the contributions were uniform.

##### So, now we know that chocolate and fruity are important, but also hard, nougat, crispedricewafer, caramel & peanutyalmondy.

#PCA with numeric variables
```{r}
res.pca = PCA(candy[,1:11], quali.sup = 1:9, scale.unit = F, ncp=2, graph = FALSE)

fviz_pca_biplot(res.pca, 
                geom.ind = c("point"))

```


In the MCA, the numeric variables seem to have little correlation to Dim1-2. A PCA with the qualitative variables as supplementary will give us an idea if there are any correlations between the quantitative and qualitative variables.

```{r}

plotellipses(res.pca, level = 0.95, 
             means = FALSE, 
             xlim = c(-1,1), ylim = c(-1, 1)
             )
var2 <- res.pca$quali.sup
corrplot::corrplot(var2$eta2, is.corr=TRUE, cl.ratio = 1, cl.lim = c(0,0.5))

```
The correlation of the categorical variables with the PCA dimensions is much less than 0.5. The variables chocolate1, fruity0, bar1, caramel1 seem to have weak correlation with Dim1-2.

##### 4.4) Is our dataset randomized?
We are not sure it is randomized, so we will shuffle it just in case:

```{r}
set.seed(123)
candy_rand <- candy[sample(1:nrow(candy)), ]
dim(candy_rand)
```

##### 4.5) Define an evaluation protocol: how many samples we have? Hold out method. Cross validation needed?

We have only 85 rows, so this is a very small dataset. We will divide the dataset into train and test sets and make sure we use cross validation when we train our model. In that way we ensure we are using our few observations as well as we can.


###Model

##Split into training & test sets
```{r}
set.seed(9)
inTrain <- createDataPartition(candy_rand$winpercent, p=0.8, list =FALSE)

ctrain <- candy_rand[inTrain,]
ctest <- candy_rand[-inTrain,]

dim(ctrain); dim(ctest)

```

#Explore the correlation of variables with winpercent
```{r}

pairs(ctrain[ ,10:12]) #pairwise plots of numeric columns

winlist  <- list()
for (i in seq_along(nm)) {
    winlist[[i]] <- ggplot(ctrain, aes_string(nm[i], "winpercent"))+ geom_boxplot(aes_string(color = nm[i]), show.legend = FALSE)
}

cutsugar <- cut2(ctrain$sugarpercent, g = 3)
table(cutsugar)

#cutprice <- cut2(ctrain$pricepercent, g =3, levels.mean = TRUE)
#table(cutprice)

#win1 <- ggplot(ctrain, aes(cutsugar, winpercent))+ geom_boxplot(aes_string(color = cutsugar))
#win2 <- ggplot(ctrain, aes(cutprice, winpercent))+ geom_boxplot(aes_string(color = cutprice))

win1 <- qplot(sugarpercent, winpercent, data = candy) + geom_point() + geom_smooth(method = lm)
win2 <- qplot(pricepercent, winpercent, data = candy) + geom_point() + geom_smooth(method = lm)


grid.arrange(grobs = winlist, top=textGrob("Winpercent by candy characteristics (train)"))
grid.arrange(win1, win2, top=textGrob("Winpercent by candy characteristics (train)"), nrow = 1)

```

Winpercent is high for some of the factor variables, but shows low correlation with the numeric variables.



```{r}
attach(ctrain)
fit1 <- lm(winpercent ~ ., data = ctrain)
summary(fit1)
```
Chocolate, fruity, peanutyalmondy and crispedricewafer have high significance in the model, which was expected. Sugarpercent also has a high significance at 0.01%. The R-squared is 0.58 and RSE is 0.102.

```{r}
plot(fit1)
```
F-statistic is significant with a small p-value, which indicates that there is a relationship between the predictors and response.
The Residuals vs Fitted values and Q-Q plot are cloe to the expected values, so it seems like a good fit and quadratic fit is not required.
There are a few outliers, but they don't have  high leverage. One quarter has medium leverage


```{r}
train1 <- predict(fit1, newdata = ctrain)
RMSE(train1, ctrain$winpercent)
qplot(ctrain$winpercent, train1) + geom_point() + geom_smooth(method = lm)
```
Overall, the basic model seems like a good fit with RMSE 0.093.


I will try changing a few parameters considering only the variables found to be highly significant in exploratory analysis
```{r}
fit2 <- lm(winpercent ~ .-pluribus-pricepercent-bar, data = ctrain)

summary(fit2)
plot(fit2)

```


```{r}
train2 <- predict(fit2, newdata = ctrain)
RMSE(train2, ctrain$winpercent) #RMSE is actually higher than before
#qplot(ctrain$winpercent, train1) + geom_point() + geom_smooth(method = lm)
```

There is not a big difference in the model fit between fit1 and fit2. The R2 is slightly lower (0.557) and RMSE is higher (0.0956).

```{r}
fit3 <- lm(winpercent ~ chocolate+ fruity+ peanutyalmondy+crispedricewafer+sugarpercent, data = ctrain)
#fit3 <- lm(winpercent ~ chocolate)

summary(fit3)
plot(fit3)

```
```{r}
train3 <- predict(fit3, newdata = ctrain)
RMSE(train3, ctrain$winpercent) #RMSE is actually higher than before
#qplot(ctrain$winpercent, train1) + geom_point() + geom_smooth(method = lm)
```
Whoppers is now an outlier with a high leverage.

Fit1 considering all the variables seems to be the best fit for the linear model.

I will run cross validation for various models using all the variables.

#Parallel processing and cross validation 

```{r}
doParallel::registerDoParallel(4) # here I'm using 4 cores from my computer
#getDoParWorkers()

set.seed(987) # for replicability

my_control <- trainControl(method = "cv", # for "cross-validation"
                           number = 5, # number of k-folds
                           savePredictions = "final",
                           allowParallel = TRUE)

```

#Train several models
```{r message=FALSE, warning=FALSE}
set.seed(222)

model_list <- caretList(winpercent ~ .,
                        data = ctrain,
                        trControl = my_control, 
                        methodList = c("lm", "rpart", "svmRadial", "rf", "xgbTree", "glm"),
                        tuneList = NULL, # no manual hyperparameter tuning
                        continue_on_fail = FALSE # stops if something fails
                        #preProcess  = c("center","scale") 
                        )
```
Now that our caretList was trained, we can take a look at the results. We can access each separate model.

```{r}
model_list$lm

```

```{r}
model_list$rpart
```

```{r}
model_list$rf

```

Let's go to our objective, which is finding the model that has the lowest root mean squared error. We first asses this for the training data.

#Random forest has the lowest RMSE
```{r}
options(digits = 3)

model_results <- data.frame(LM = min(model_list$lm$results$RMSE),
                            SVM = min(model_list$svmRadial$results$RMSE),
                            RPART= min(model_list$rpart$results$RMSE),
                            RF = min(model_list$rf$results$RMSE),
                            XGBT = min(model_list$xgbTree$results$RMSE),
                            GLM = min(model_list$glm$results$RMSE))


print(model_results)
```

RandomForest gives the lowest RMSE of 0.105. The mean for winpercent is about 0.5.

```{r}
resamples <- resamples(model_list)

dotplot(resamples, metric = "RMSE", title = "Dotplot for RMSE")
dotplot(resamples, metric = "Rsquared", title = "Dotplot for Rsquared")

```

```{r}
modelCor(resamples)

```

```{r}
set.seed(222)
ensemble_1 <- caretEnsemble(c(model_list$lm, model_list$rf, model_list$svmRadial), 
                            metric = "RMSE", 
                            trControl = my_control)
summary(ensemble_1)
```
The RMSE (0.1065) of the ensemble model is similar (in fact, higher) than the best model.


```{r}
randf <- model_list$rf
model_list$rf$modelInfo
library(randomForest)
head(getTree(randf$finalModel, 1))

importance(randf$finalModel)
varImpPlot(randf$finalModel)
```


###Future Directions

- The experiment design to pick winner from matchups might not be an optimal way to judge customer satisfaction. Instead sales would be a better variable.
- Actual sugarcontent and price instead of an ordinal variable
